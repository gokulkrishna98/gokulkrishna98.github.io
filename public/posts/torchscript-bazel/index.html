<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Torch Script Bazel | Gokul's Website</title>
<meta name=keywords content><meta name=description content="In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.
The Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation here
In this article, we will be using Bazel to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application."><meta name=author content="Gokul"><link rel=canonical href=http://localhost:1313/posts/torchscript-bazel/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/torchscript-bazel/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="http://localhost:1313/posts/torchscript-bazel/"><meta property="og:site_name" content="Gokul's Website"><meta property="og:title" content="Torch Script Bazel"><meta property="og:description" content="In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.
The Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation here
In this article, we will be using Bazel to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-14T00:00:00+00:00"><meta property="article:modified_time" content="2024-08-14T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Torch Script Bazel"><meta name=twitter:description content="In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.
The Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation here
In this article, we will be using Bazel to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"Torch Script Bazel","item":"http://localhost:1313/posts/torchscript-bazel/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Torch Script Bazel","name":"Torch Script Bazel","description":"In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.\nThe Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation here\nIn this article, we will be using Bazel to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application.\n","keywords":[],"articleBody":"In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.\nThe Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation here\nIn this article, we will be using Bazel to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application.\nPrerequisites Install bazelisk and check if you can print the version. Installation instruction can be found here (base) gokul@gokul-linux-inpiron16:GGlow$ bazel --version bazel 6.1.2 Install python and pytorch (recommend using miniconda) (ml) gokul@gokul-linux-inpiron16:GGlow$ python --version Python 3.10.0 (ml) gokul@gokul-linux-inpiron16:GGlow$ python3 Python 3.10.0 (default, Mar 3 2022, 09:58:08) [GCC 7.5.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e import torch \u003e\u003e\u003e print(torch.__version__) 2.2.1+cu121 Have C++ compiler installed that supports C++17. Setting up the Bazel C++ projects First let us create a project. Let us specify the C++17 compilation option and the bazel version to be used.\nCreate a .bazelrc and add the following build --action_env=BAZEL_CXXOPTS=-std=c++17 Create a .bazelversion to mention the bazel version. 6.1.2 Now let us create a Workspace file that can download the torchscript. The workspace file is responsible for specifying the external dependencies needed for the project. It can do lot of cool stuff, with certain rules and maintains the project via online project and stops us from maintaining external dependencies locally.\nCreate a WORKSPACE file in the root directory, with the following. workspace(name = \"bazel_example\") load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\") # ADDING TORCHSCRIPT DEPENDENCIES http_archive( name = \"libtorch\", strip_prefix = \"libtorch\", sha256 = \"9d16cc0da41e057f20c0be5f26d7418f969e857631cfcb86550ccdecfee8de60\", urls = [\"https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-2.4.0%2Bcpu.zip\"], build_file = \"//third_party/torchscript:libtorch.BUILD\", ) The URL and the SHA can be calculated from pytorch website: here . By Choosing libtorch package -\u003e C++ -\u003e Run this command (you will find link here and add it to urls in the http_archive for libtorch). For sha256, calculate it using sha256 checksum tool.\nNext, we have to write bazel rules to read the torch script, shared objects, header files to add it as dependency. Create a folder called third_party/torchscript and create the following files:\nempty BUILD. a libtorch.BUILD file, to read the external library. cc_library( name = \"libtorch\", srcs = [ \"lib/libtorch.so\", \"lib/libc10.so\", \"lib/libbackend_with_compiler.so\", \"lib/libtorch_cpu.so\", \"lib/libnnapi_backend.so\", \"lib/libtorch_global_deps.so\", \"lib/libtorchbind_test.so\", \"lib/libjitbackend_test.so\", \"lib/libshm.so\", \"lib/libtorch_python.so\", \"lib/libgomp-98b21ff3.so.1\" ], linkopts = [ \"-ltorch\", \"-lc10\", \"-lbackend_with_compiler\", \"-ltorch_cpu\", \"-lnnapi_backend\", \"-ltorch_global_deps\", \"-ltorchbind_test\", \"-ljitbackend_test\", \"-lshm\", \"-ltorch_python\", \"-lpython3.10\", \"-lgomp\" ], hdrs = glob([\"include/**/*.h\"]), includes = [ \"include\", \"include/torch/csrc/api/include\" ], copts = [\"-D_GLIBCXX_USE_CXX11_ABI=1\"], visibility = [\"//visibility:public\"], ) Let us create a source file, which uses pytorch C++ front-end to print the model: src/main.cpp\n#include #include auto main() -\u003e int { std::string model_path = \"./resnet18.pt\"; auto module = torch::jit::load(model_path); module.dump(false, false, false); return 0; } write a build file to build the src file.\ncc_binary( name = \"main\", srcs = [\"main.cpp\"], deps = [ \"@libtorch//:libtorch\" ], ) The resnet model is a model that has been serialized by pytorch, you can generate any pytorch model to this model file by following similar python script:\nimport torch model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True) model.eval() input = torch.rand(1, 3, 224, 224) traced_script_module = torch.jit.trace(model, input) traced_script_module.save(\"../models/resnet18.pt\") Now our project structure, should look like this:\n├── src │ ├── BUILD │ ├── main.cpp │ └── resnet18.pt ├── third_party │ ├── BUILD │ └── torchscript │ ├── BUILD │ └── libtorch.BUILD └── WORKSPACE Now we can build the project:\nbazel build src:all Now copy the model file to the location of the binary.\ncp src/resnet18.pt bazel-bin/src/ Then run the binary\ncd bazel-bin/src/main ./main Thats all, you can find the part of the project in the project: https://github.com/gokulkrishna98/GGlow\n","wordCount":"635","inLanguage":"en","datePublished":"2024-08-14T00:00:00Z","dateModified":"2024-08-14T00:00:00Z","author":{"@type":"Person","name":"Gokul"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/torchscript-bazel/"},"publisher":{"@type":"Organization","name":"Gokul's Website","logo":{"@type":"ImageObject","url":"http://localhost:1313/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Gokul's Website (Alt + H)">Gokul's Website</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Torch Script Bazel</h1><div class=post-meta><span title='2024-08-14 00:00:00 +0000 UTC'>August 14, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;635 words&nbsp;·&nbsp;Gokul</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#prerequisites>Prerequisites</a></li><li><a href=#setting-up-the-bazel-c-projects>Setting up the Bazel C++ projects</a></li></ul></nav></div></details></div><div class=post-content><p>In this article, we will be exploring how to use PyTorch in C++. The Python has lots of overhead and baggage when using in application where the performance is critical, for example in game engines, embedded device application, use of python as front end is bad.</p><p>The Pytorch provides us C++ front-end APIs and library to write ML application in a static compiled language. You can find documentation <a href=https://pytorch.org/cppdocs/>here</a></p><p>In this article, we will be using <a href=https://bazel.build/start/cpp>Bazel</a> to build a C++ project which can use Pytorch APIs. The main goal is to read a ML model that has been exported from Pytorch (python) using a C++ application.</p><h2 id=prerequisites>Prerequisites<a hidden class=anchor aria-hidden=true href=#prerequisites>#</a></h2><ul><li>Install bazelisk and check if you can print the version. Installation instruction can be found <a href=https://bazel.build/install/bazelisk>here</a></li></ul><pre tabindex=0><code>(base) gokul@gokul-linux-inpiron16:GGlow$ bazel --version
bazel 6.1.2
</code></pre><ul><li>Install python and pytorch (recommend using miniconda)</li></ul><pre tabindex=0><code>(ml) gokul@gokul-linux-inpiron16:GGlow$ python --version
Python 3.10.0
(ml) gokul@gokul-linux-inpiron16:GGlow$ python3 
Python 3.10.0 (default, Mar  3 2022, 09:58:08) [GCC 7.5.0] on linux
Type &#34;help&#34;, &#34;copyright&#34;, &#34;credits&#34; or &#34;license&#34; for more information.
&gt;&gt;&gt; import torch
&gt;&gt;&gt; print(torch.__version__)
2.2.1+cu121
</code></pre><ul><li>Have C++ compiler installed that supports C++17.</li></ul><h2 id=setting-up-the-bazel-c-projects>Setting up the Bazel C++ projects<a hidden class=anchor aria-hidden=true href=#setting-up-the-bazel-c-projects>#</a></h2><p>First let us create a project. Let us specify the C++17 compilation option and the bazel version to be used.</p><ul><li>Create a <code>.bazelrc</code> and add the following</li></ul><pre tabindex=0><code>build --action_env=BAZEL_CXXOPTS=-std=c++17
</code></pre><ul><li>Create a <code>.bazelversion</code> to mention the bazel version.</li></ul><pre tabindex=0><code>6.1.2
</code></pre><p>Now let us create a Workspace file that can download the torchscript. The workspace file is responsible for specifying the external dependencies needed for the project. It can do lot of cool stuff, with certain rules and maintains the project via online project and stops us from maintaining external dependencies locally.</p><ul><li>Create a <code>WORKSPACE</code> file in the root directory, with the following.</li></ul><pre tabindex=0><code>workspace(name = &#34;bazel_example&#34;)

load(&#34;@bazel_tools//tools/build_defs/repo:http.bzl&#34;, &#34;http_archive&#34;)

# ADDING TORCHSCRIPT DEPENDENCIES
http_archive(
    name = &#34;libtorch&#34;,
    strip_prefix = &#34;libtorch&#34;,
    sha256 = &#34;9d16cc0da41e057f20c0be5f26d7418f969e857631cfcb86550ccdecfee8de60&#34;,
    urls = [&#34;https://download.pytorch.org/libtorch/cpu/libtorch-cxx11-abi-shared-with-deps-2.4.0%2Bcpu.zip&#34;],
    build_file = &#34;//third_party/torchscript:libtorch.BUILD&#34;,
)
</code></pre><p>The URL and the SHA can be calculated from pytorch website: <a href=https://pytorch.org/>here</a> . By Choosing <code>libtorch</code> package -> C++ -> Run this command (you will find link here and add it to <code>urls</code> in the <code>http_archive</code> for <code>libtorch</code>). For <code>sha256</code>, calculate it using <code>sha256</code> checksum tool.</p><p><img alt="pytorch install" loading=lazy src=/images/pytorch_myscript.png></p><p>Next, we have to write bazel rules to read the torch script, shared objects, header files to add it as dependency. Create a folder called <code>third_party/torchscript</code> and create the following files:</p><ul><li>empty <code>BUILD</code>.</li><li>a <code>libtorch.BUILD</code> file, to read the external library.</li></ul><pre tabindex=0><code>cc_library(
    name = &#34;libtorch&#34;,
    srcs = [
        &#34;lib/libtorch.so&#34;,
        &#34;lib/libc10.so&#34;,
        &#34;lib/libbackend_with_compiler.so&#34;,
        &#34;lib/libtorch_cpu.so&#34;,
        &#34;lib/libnnapi_backend.so&#34;,
        &#34;lib/libtorch_global_deps.so&#34;,
        &#34;lib/libtorchbind_test.so&#34;,
        &#34;lib/libjitbackend_test.so&#34;,
        &#34;lib/libshm.so&#34;,
        &#34;lib/libtorch_python.so&#34;,
        &#34;lib/libgomp-98b21ff3.so.1&#34;
    ],
    linkopts = [
        &#34;-ltorch&#34;,
        &#34;-lc10&#34;,
        &#34;-lbackend_with_compiler&#34;,
        &#34;-ltorch_cpu&#34;,
        &#34;-lnnapi_backend&#34;,
        &#34;-ltorch_global_deps&#34;,
        &#34;-ltorchbind_test&#34;,
        &#34;-ljitbackend_test&#34;,
        &#34;-lshm&#34;,
        &#34;-ltorch_python&#34;,
        &#34;-lpython3.10&#34;,
        &#34;-lgomp&#34;
    ],
    hdrs = glob([&#34;include/**/*.h&#34;]),
    includes = [
        &#34;include&#34;,
        &#34;include/torch/csrc/api/include&#34;
    ],
    copts = [&#34;-D_GLIBCXX_USE_CXX11_ABI=1&#34;],
    visibility = [&#34;//visibility:public&#34;],
)
</code></pre><p>Let us create a source file, which uses pytorch C++ front-end to print the model: <code>src/main.cpp</code></p><pre tabindex=0><code>#include &lt;torch/script.h&gt;
#include &lt;torch/torch.h&gt;

auto main() -&gt; int {
	std::string model_path = &#34;./resnet18.pt&#34;;
	auto module = torch::jit::load(model_path);
	module.dump(false, false, false);
	
	return 0;
}
</code></pre><p>write a build file to build the src file.</p><pre tabindex=0><code>cc_binary(
	name = &#34;main&#34;,
	srcs = [&#34;main.cpp&#34;],
	deps = [
		&#34;@libtorch//:libtorch&#34;
	],
)
</code></pre><p>The <code>resnet</code> model is a model that has been serialized by pytorch, you can generate any pytorch model to this model file by following similar python script:</p><pre tabindex=0><code>import torch

model = torch.hub.load(&#39;pytorch/vision:v0.10.0&#39;, &#39;resnet18&#39;, pretrained=True)
model.eval()

input = torch.rand(1, 3, 224, 224)
traced_script_module = torch.jit.trace(model, input)

traced_script_module.save(&#34;../models/resnet18.pt&#34;)
</code></pre><p>Now our project structure, should look like this:</p><pre tabindex=0><code>├── src
│   ├── BUILD
│   ├── main.cpp
│   └── resnet18.pt
├── third_party
│   ├── BUILD
│   └── torchscript
│       ├── BUILD
│       └── libtorch.BUILD
└── WORKSPACE
</code></pre><p>Now we can build the project:</p><pre tabindex=0><code>bazel build src:all
</code></pre><p>Now copy the model file to the location of the binary.</p><pre tabindex=0><code>cp src/resnet18.pt bazel-bin/src/
</code></pre><p>Then run the binary</p><pre tabindex=0><code>cd bazel-bin/src/main
./main
</code></pre><p>Thats all, you can find the part of the project in the project: <a href=https://github.com/gokulkrishna98/GGlow>https://github.com/gokulkrishna98/GGlow</a></p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Gokul's Website</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>